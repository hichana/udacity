---
title: "R for Data Science 4 and 5"
author: "Matt Chana"
date: "5/29/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 4.3 Calling Functions
Shorten a assingment/call and print statement to one line.

Start with:
```{r}
y <- seq(1,10, length.out = 5)
y
```

Make into:
```{r}
(y <- seq(1,10, length.out = 5))
```

```{r}
my_variable <- 10
my_variable
```

# 5.1 Introduction
Data is often not even ready for visualizations, so it'll need to be transformed. First, load the data (note, some functions from imports may conflict with base R functions, in which case the overwritten function would need to be explicity stated via the library_I'm_referencing::function_I'm_calling() method):
```{r}
library(nycflights13)
library(tidyverse)
```

Check out nycflights13 package's flights dataframe:
```{r}
flights
```

View the whole dataset in the RStudio viewer:
```{r}
# View(flights)
```

Note, R uses factors (abbrev. `fctr`), which represent categorical variables with fixed possible values.

### 5.1.3 dplyr basics
The five key functions of dplyr, filter(), arrange(), slect(), mutate() and summarise(), can be used in conjunction with group_by() to chnage the scope of each function.

### 5.2 Filter Rows with `filter()`
`filter()` subsets observations based on their values. Filter flights for any flights from a Janauary 1st:
```{r}
jan_1st <- filter(flights, month == 1, day == 1)
jan_1st
```

Computers use finite precision arithmetic - so irrational numbers, or numbers that have enough trailing digits as decimals may result in incorrect results. So make this:
```{r}
sqrt(2) ^ 2 == 2
```

into this with the near() function:
```{r}
near(sqrt(2) ^ 2, 2)
```

### 5.2.2 Logical Operators
All flights departed in November or December:
```{r}
nov_dec <- filter(flights, month == 11 | month == 12)
nov_dec
```

I'll double check to make sure it worked by finding the unique values in the `month` variable:
```{r}
unique(nov_dec$month)
```

Great, months 11 and 12 are there as expected. Another way to filter, using %in%, which looks at the month variable and returns all values from the specified vector:

```{r}
nov_dec_in <- filter(flights, month %in% c(11, 12))
nov_dec_in
```

And to double check:
```{r}
unique(nov_dec_in$month)
```

Find flights that weren't delayed (on arrival or departure) by more than two hours:
```{r}
filter(flights, !(arr_delay > 120 | dep_delay > 120))
```

Or:
```{r}
filter(flights, arr_delay <= 120, dep_delay <= 120)
```

Note, `filter()` **excludes** rows where the condition is `FALSE` or `NA`.
```{r}
tib <- tibble(x = c(1, 2, NA, 3))
tib
```

Wait, what is a `tibble`? It differs from dataframe in printing and setting. Prints only first 10 rows on screen, and is scrict about subsetting - so gives an error if variable being accessed dos not exist, and clearly delineates bracketing while always returning another tibble.

So back to filtering:
```{r}
filter1 <- filter(tib, x > 1)
filter1
```

If you want the NA values, must be explicit:
```{r}
filter2 <- filter(tib, is.na(x) | x > 1)
filter2
```

### 5.2.4 Exercises
TODO

### 5.3 Arrange rows with `arrange()`
Works like `filter()` except instead of selecting rows it changes order. 
```{r}
arrange(flights, year, month, day)
```

Use `desc()` to re-order in descending order:
```{r}
arrange(flights, desc(arr_delay))
```

Note, NA is always sorted at the end no matter if ascendinng or descending:
```{r}
sort_na <- arrange(tib, desc(x))
sort_na
```

### 5.3.1 Exercises
TODO

### 5.4 Select Columns with `select()`
```{r}
col_select <- select(flights, year, month, day)
col_select
```


Select a range of columns (inclusive):
```{r}
col_range <- select(flights, year:day)
col_range
```

Select all except in a range:
```{r}
col_range <- select(flights, -(year:day))
col_range
```

Helper functions used within `select()`:

* starts_with("abc"): matches names that begin with “abc”.

* ends_with("xyz"): matches names that end with “xyz”.

* contains("ijk"): matches names that contain “ijk”.

* matches("(.)\\1"): selects variables that match a regular expression.

`Select()` can be used to rename variables, but better option is to use `rename()`:
```{r}
# changes 'tailnum' to 'tail_num'
  # notice variable accessed on right of equal sign
rename(flights, tail_num = tailnum)
```

Change order of dataframe via `select()` and `everything()`:
```{r}
reorder_flights <- select(flights, time_hour, everything())
reorder_flights
```

 ### 5.4.1 Exercises
 TODO
 
 ### 5.5 Add New Variabels with `mutate()`
 First create a smaller dataframe to play with:
 
```{r}
flights_sml <- select(flights,
                      year:day,
                      ends_with("delay"),
                      distance,
                      air_time)
flights_sml
```

Now perform vectorized operations:
```{r}
flights_sml2 <- mutate(flights_sml,
       gain = arr_delay - dep_delay,
       speed = distance / air_time * 60,
       hours = air_time / 60,
       gain_per_hour = gain / hours)
names(flights_sml2)
flights_sml2
```

Use `transmute()` to only keep the new variables:
```{r}
my_comps <- transmute(
 flights,
 gain = arr_delay - dep_delay,
 hours = air_time / 60,
 gain_per_hour = gain / hours
)

my_comps
```

Separate hour and minute in dep_time variable:
```{r}
departure_times <- transmute(
  flights,
  dep_time,
  hour = dep_time %/% 100,
  minute = dep_time %% 100
)
departure_times
```

Note, %/% is for integer division and %% is for remainder division.

Aggregation functions like `sum()` and other mathematical funcitons, anything really, can be used in the vectorized operations.

Logarithms are useful for transforming data that ranges across multiple orders of magnitude (`log2()` is recommended  because easy to interpret - where a difference of 1 on the log scale corresponds to doubling on the original scale and a difference of -1 corresponds to halving):

* `log()`
* `log2()`
* `log10()`

Offsets, lead and lag:
```{r}
x <- 1:10
x
```
```{r}
lag(x)
```

```{r}
lead(x)
```

Cumulative and rolling aggregates:

* `cumsum()`
* `cumprod()`
* `cummax()`
* `cummean()` (from dplyr)

```{r}
x
```
```{r}
# cumulative sum across the data
cumsum(x)
```
```{r}
cummean(x)
```

Ranking - smallest values get small ranks:
```{r}
y <- c(1, 2, 2, NA, 3, 4)
min_rank(y)
```

Ranking - smallest values get large ranks:
```{r}
min_rank(desc(y))
```

Variants for raking:
```{r}
row_number(y)
dense_rank(y)
percent_rank(y)
cume_dist(y)
```

### 5.5.2 Exercises
TODO

### 5.6 Grouped Summaries with `summarize()`
Collapses a dataframe into a single row:
```{r}
# note, na.rm set to TRUE strips NA values before computation
summarize(flights, delay = mean(dep_delay, na.rm = TRUE))
```

A grouped summary - find average delay per date using `summarize()` and `group_by()`:
```{r}
by_day <- group_by(flights, year, month, day)
summarize(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

### 5.6.1 Combining Multiple Operations with the Pipe
We want to explore the relationship between the distance and average delay for each location. Check out flights dataframe again:
```{r}
flights
```

So `distance` has doubles like 1400, 1416, etc. `dest` has characters like 'IAH", 'MIA', `dep_delay` and `arr_delay` have doubles like 11, -1, etc. 

To find the relationship I'm looking for I'll need to

* group by destination
* summarize to compute the distance, average delay and number of flights
* I'll need to filter to remove noisy points and Honolulu airport which is twice as far away as the next closest airport. 

Here I'm specifying the groups, but because I'm not performing an operation yet, it still looks like the original.
```{r}
by_dest <- group_by(flights, dest)
by_dest
```

Before applying aggregation function, learn a few functions. So I know I can focus on a variable:
```{r}
unique(flights$year)
```

And I can use `group_by` to specify the grouping logic:
```{r}
grouped_by_flights <- group_by(
  flights,
  year
)
grouped_by_flights
```

Notice the same number of rows - the `group_by()` function - I've specified the logic but haven't implemented an aggregation function yet so nothing has actually happened. When I apply an aggregation function via `summarize()`, the aggregation function is applied to the grouping logic.

Number of observations in the current group:
```{r}
summarize(
  grouped_by_flights,
  count = n()
)
```

Note, I've grouped by year, used that in my summarize/aggregation function of `n()` to count the number of observations in the current group. If I would have grouped by destination I would get a dataframe with a list of destinations in one column with a count for each. Try more:
```{r}
summarize(
  grouped_by_flights,
  dist = mean(distance, na.rm = TRUE)
)
```

Here, because I'm grouping by just the one year, I get the mean distance for the whole dataset's `distance` variable. I'll check this by using the `mean()` function on the original dataframe's 'distance' variable without any grouping:
```{r}
mean(flights$distance)
```

Indeed, it's the same. 

Now I'll apply my aggregation functions/perform vectorized operations via `summarize()`, using my group_by dataframe:
```{r}
delay <- summarize(
  by_dest,
  # number of operations in the current group
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
delay
```

Now I have 105 destinations with their count, mean distance and mean arrival delay. Now I want to filter for number of observations greater than 20, and exclude Honolulu:
```{r}
delay <- filter(delay, count > 20, dest != "HNL")
delay
```

I'm left with 96 rows, that I can now plot to see the relationship between distance and arrival delay:
```{r}
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = FALSE)
```

This is an extraneous amount of code because I don't really need/care about each intermediate dataframe. So focusing on the transformations instead of what's being transformed, the whole shebang can be distilled using the pipe, `%>%` (can be thought of as imperative statements followed by the word "then"):

```{r}
delays <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")

delays
```

### 5.6.2 Missing Values
What happens if you don't set the `na.rm` parameter in some functions?
```{r}
flights %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay))
```

What's going on here? Look at the `dep_delay` variable first:
```{r}
jan_1 <- subset(flights, month == 1 & day == 1)
jan_1
```

So there were 842 flights on January 1st 2013. What are the unique values in dep-delay?
```{r}
unique(jan_1$dep_delay)
```

I see at least one of these flights has an NA in its `dep_delay`. Now check another day:
```{r}
jan_2 <- subset(flights, month == 2 & day == 1)
jan_2
```

Ok, 926 flights on January 2nd. Is there an NA in the `dep_delay` variable for this day too?
```{r}
unique(jan_2$dep_delay)
```

Yes there is! 

Now remember the rule with aggregation functions is that if there is and NA anywhere in the space it will resolve to NA. So I expect that if I group by and then apply an aggregation via `summarize()` that I will have two or more NA's as a result. That's what happened! Now, adding the `na.rm` parameter I get what I want:
```{r}
flights %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay, na.rm = TRUE))
```

It turns out the NA in this dataset represent canceled flights. Removing the cancelled flights, first create dataframe:
```{r}
not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled
```

Now group by and summarize/aggrregate using my new dataframe:
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay))
```

### 5.6.3 Counts
When doing aggregation, good idea to include a count of missing values to make sure not drawing conclusions based on small amounts of data. Example, planes with highest average delays:
```{r}
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay))
delays

ggplot(data = delays, mapping = aes(x = delay)) +
  geom_freqpoly(binwidth = 10)
```

Here, the mean arrival delays are grouped in bins of width 10 - so the vast majority of them were either a little early or less than about 25 minutes late arriving. But, some planes have an averave of over 300 minutes delay! But the story is a little more nuanced - draw a scatter plot to get more insights:
```{r}
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )
delays
```

Now, plot:
```{r}
ggplot(data = delays, mapping = aes(x = n, y = delay)) +
  geom_point(alpha = 1/10)
```

Note the variation decreases as the sample size increases - a common characteristic of plotting a mean (or other summary) vs. group size. Can filter out the groups with the smallest number of observations to see more of the pattern and less of the etreme varition (note, following code implements `ggplot` into the `dplyr` flow):
```{r}
delays %>%
  filter(n > 25) %>%
  ggplot(mapping = aes(x=n, y = delay)) +
    geom_point(alpha = 1/10)
```

Same pattern with average performance of batters in baseball related to number of times at bat. First, check out the dataframe:
```{r}
batting <- as_tibble(Lahman::Batting)
batting
```

Now group and summarize/aggregate:
```{r}
batters <- batting %>%
  group_by(playerID) %>%
  summarize(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    ab = sum(AB, na.rm = TRUE)
  )
batters
```

Now plot:
```{r}
batters %>%
  filter(ab > 100) %>%
  ggplot(mapping = aes(x = ab, y = ba)) +
  geom_point() +
  geom_smooth(se = FALSE)
```

Like the other plot, the variation in my chosen aggregate decreases as we get more data points. Also, there's a positive correlation between skill (ba) and opportunities to hit the ball (ab). Obvious explanation is that teams choose who bats, and the ones with best batting average will be chosen to bat more.

Important implications for ranking - if naively sorting on `desc(ba)`, people with best batting averages are clearly lucky, not skilled:
```{r}
batters %>%
  arrange(desc(ba))
```

See, people with only 1 at-bat got lucky here!

### 5.6.4 Useful Summary Functions
Measures of location:

* `mean(x)`
* `median(x)`

Practice combining aggregation with logical subsetting:
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    avg_delay1 = mean(arr_delay),
    avg_delay2 = mean(arr_delay[arr_delay > 0])
  )
```

Measures of spread:

* `sd(x)` (standard deviation)
* `IRQ(x)` (interquartile range)
* `mad(x)` (mean absolute deviation)

```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarize(distance_sd = sd(distance)) %>%
  arrange(desc(distance_sd))
```

Measures of rank:

* `min(x)`
* `quantile(x, 0.25)` (will find a value of `x` that is greater than 25% of the values and less than the remaining 75%)
* `max(x)`
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    first = min(dep_time),
    last = max(dep_time)
  )
```

Measures of position:

* `first(x)`
* `nth(x, 2)`
* `last(x)`

They work like `x[1]`, `x[2]`, and `x[length(x)]` except you can set a default values if that position does not exist.
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first_dep = first(dep_time), 
    last_dep = last(dep_time)
  )
```

These functions are complimentary to filtering on ranks, but with filtering you get each observation in a separate row:
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  mutate(r = min_rank(desc(dep_time))) %>% 
  filter(r %in% range(r))
```

Count:

* `n()`
* `sum(!is.na(x))`
* `n_distinct(x)`

Destinations with most carriers:
```{r}
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  arrange(desc(carriers))

```

Just count number of flights to each destination:
```{r}
not_cancelled %>% 
  count(dest)
```

Add a weight - so count total numbers of miles a plane flew:
```{r}
not_cancelled %>% 
  count(tailnum, wt = distance)
```

Number of flicths leaving before 5am:
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(n_early = sum(dep_time < 500))
```

Proportion of flights delayed more than one hour:
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(hour_perc = mean(arr_delay > 60))
```

### Grouping by Multiple Variables:
Flights per day:
```{r}
daily <- group_by(flights, year, month, day)
per_day <- summarize(daily, flights = n())
per_day

per_month <- summarize(per_day, flights = sum(flights))
per_month

per_year <- summarize(per_month, flights = sum(flights))
per_year
```

### Ungrouping
Return to operations on ungrouped data:
```{r}
daily %>%
  ungroup() %>%
  summarize(flights = n())
```

### 5.6.7 Exercises
TODO

### Grouped Mutates (and filters)
`mutate()` and `filter()` can also be used when grouping. Find the worst members of each group:
```{r}
flights_sml %>%
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

All groups bigger than a threshold:
```{r}
popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests
```

Standardize to compute per group metrics:
```{r}
popular_dests %>% 
  filter(arr_delay > 0) %>% 
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
  select(year:day, dest, arr_delay, prop_delay)
```

Grouped filter is a grouped mutate followed by an ungrouped filter. Usually avoid except for quick and dirty manipulations.

### 5.7.1 Exercises
TODO





