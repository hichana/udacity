---
title: "R for Data Science 7"
author: "Matt Chana"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

### 7.1 Introduction
Use visualization and transformation to explore data systematically. EDA is very iterative.

* generate questions about the data
* search for answers by visualizing, transforming and modeling
* use learnings to refine questions and/or generate new ones

EDA is a state of mind, not a formal process. Some ideas will pan out - others dead ends. Even if questions/investigation already provided, will need to clean data, which requires all tools of EDA: vizualization, transformation, modeling.

### 7.2
Questions used as tools to guide investigation. EDA is creative process! Difficult to ask many questions at beginning b/c don't know insights contained in the data yet. Two types of useful questions:

* What type of variation occurs within my variables?
* What type of covariation occurs between my variables?

In tabular data, variable is the column, value is a single item from the column, an observation is the whole row.

### 7.3.1
A variable is categorical if it can only take one of a small set of values - usually saved as factors or character vectors. Best visualized in bar chart with height determined by number of observations for each category. 

Visualize with bar chart:
```{r}
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut))
```

Count values in a categorical variable:
```{r}
diamonds %>%
  count(cut)
```

A variable is continuous if it can take any of an infinite set of ordered values (ex. numbers or date-times). Use histogram to visualize:
```{r}
ggplot(data = diamonds) +
  geom_histogram(mapping = aes(x = carat), binwidth = 0.5)
```

Count the items in each bin:
```{r}
diamonds %>%
  # cut_width() notes a range for each value
  # count() groups and counts
  count(cut_width(carat, 0.5))
```

Filter based on carat size first, then plot:
```{r}
smaller <- diamonds %>%
  filter(carat < 3)

ggplot(data = smaller, mapping = aes(carat)) +
  geom_histogram(binwidth = 0.1)
```

`geom_freqpoly()` can be better way to visualize multiple histograms. Example, carat size plotted by cut:
```{r}
ggplot(data = smaller, mapping = aes(x = carat, color = cut)) +
  geom_freqpoly(binwidth = 0.1)
```

### 7.3.2
When looking at bar charts and histograms:

* Which values are most common? Why?
* Which values are rare? Why? Does that match expectations?
* Are there unusual patterns? What might explain them?

This histogram...
```{r}
ggplot(data = smaller, mapping = aes(x = carat)) +
  geom_histogram(binwidth = 0.01)
```

raises some questions:

* Why more diamonds at whole carats and common fractions of carats?
* Why positive skew near each of the peaks?

Clusters suggest subgroups:

* How are observations within each cluster similar to each other?
* How are observtions in separate clusters different from each other?
* How can the cluster be described and/or explained?
* Why might the appearance of clusters be misleading?

Old faithful eruptions:
```{r}
ggplot(data = faithful, mapping = aes(x = eruptions)) +
  geom_histogram(binwidth = 0.25)
```

Why the clustering here?

### 7.3.3 Unusual values
Outliers may be data entry errors, or they may suggest important new science! Sometimes difficult to visualize, like dist of `y` variable from diamonds dataset:
```{r}
ggplot(diamonds) +
  geom_histogram(mapping = aes(x = y), binwidth = 0.5)
```

Zoom in on y-axis using `coord_cartesian()`:
```{r}
ggplot(diamonds) +
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))
```

Note, `coord_cartesian()` doesn't throw away values, but ggplot2's `xlim()` and `ylim()` do.

Pluck out the unusual values at about 0, 32 and 59 using `dplyr`:
```{r}
unusual <- diamonds %>%
  filter(y < 3 | y > 20) %>%
  select(price, x, y, z) %>%
  arrange(y)
unusual
```

`y` variable measures one of the three dimensions of the diamonds in mm. There can't be one with a 0.0 width. 31.8 and 58.9 are large, but don't cost hundreds of thousands of dollars, so also incorrect. Decide what to do with outliers based on what is learned.

7.3.4 Exercises
TODO

### 7.4 Missing Values
If finding unusual or irrelevant values in dataset, can drop entire row with the strange values easily with `filter()` and `between()` functions:
```{r}
diamonds2 <- diamonds %>%
  filter(between(y, 3, 20))
diamonds2
```

Or, can replace unusual values with missing values using `mutate()` to replace a variable with a modified copy - use `ifelse()` funciton to replace unusual values with `NA`;
```{r}
diamonds2 <- diamonds %>%
  # mutate performs the vectorized operation
    # ifelse(logic_test, if_yes, if_no)
  # ifelse performs the logic
  mutate(y = ifelse(y < 3 | y > 20, NA, y))
diamonds2
```

Find the observations with NA in the `y` variable:
```{r}
filter(diamonds2, is.na(diamonds2$y))
```

ggplot will warn if missing values:
```{r}
ggplot(diamonds2, mapping = aes(x = x, y = y)) +
  geom_point()
```

Supress the warning:
```{r}
ggplot(diamonds2, mapping = aes(x = x, y = y)) +
  geom_point(na.rm = TRUE)
```

Find out what makes an observation have missing values - looking at `nycflights13::flights`, if `dep_time` is NA it means a plane never departed, so it was probably canceled. Double check to make sure there are `NA` in `dep_time`:
```{r}
filter(nycflights13::flights, is.na(dep_time))
```

So there are, good. Now use `mutate()` to make new variables:
```{r}
flights2 <- nycflights13::flights %>%
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  )
flights2
```

Now plot scheduled departure time by whether or not the flight was cancelled:
```{r}
  ggplot(flights2, aes(sched_dep_time)) +
    geom_freqpoly(aes(color = cancelled), binwidth = 1/4)
```

This is not an ideal plot because large difference between the cancelled flights. Will learn how to handle in next section.

### 7.4.1 Exercises
TODO

### 7.5 Covariation
### 7.5.1 A Categorical and Continuous Variable
Common to want to plot a continuous variable broken down by a categorical vairable - but problematic if one category large and another small in count. Example:
```{r}
ggplot(data = diamonds, mapping = aes(x = price)) +
  geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
```

Note, overall counts differ by a lot:
```{r}
ggplot(diamonds) +
  geom_bar(mapping = aes(x = cut))
```

To make a better comparison between the cuts, plot the density (standardizes the area under each frequency polygot to be one):
```{r}
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) +
  geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
```

Appears fiar diamonds (lowest quality) may have the highest average price - maybw because frequency polygons are hard to interpret. Try a boxplot:

* box stretches from 25th percentile of distribution to the 75th - known as the interquartile range. Line in box is median. Gives feel of spread of the distribution and whether symmetrical about the median. Observations more than 1.5 times the IQR from either edge of the box plotted as a point (unusual so plotted individually). Whiskers extend to farthest non-outlier points of dist:
```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_boxplot()
```

This confirms counterintuitive idea from the frequency polygons with density - ideal cut diamonds are on average cheaper than fair cut ones. Goal here is to figure out why. These categories alrady organized, but sometimes will need to organize. Example, in the `mpg` dataset:
```{r}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
  geom_boxplot()
```

Reorder based on median `hwy` value to make easier to read:
```{r}
ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy))
```

Can also plot horizontally:
```{r}
ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) +
coord_flip()
```

### 7.5.1 Exercises
TODO

### 7.5.2 Two Categorical Variables:

Plot dot sizes representing count the number of observations for each combination between two variables:
```{r}
ggplot(diamonds) +
  geom_count(aes(x = cut, y = color))
```

Use `dplyr` to compute the counts - one variable:
```{r}
diamonds %>%
  count (color)
```

Two variables:
```{r}
diamonds %>%
  count(color, cut)
```

`dplyr` automatically breaks apart cut for each value from color. Now plot it with tiles:
```{r}
diamonds %>%
  count(color, cut) %>%
  ggplot(mapping = aes(x = color, y = cut)) +
    geom_tile(mapping = aes(fill = n))
```

### 7.5.2.1 Exercises
TODO

### 7.5.3 Two Continuous Variables

Review - scatter plot with two continuous variables:
```{r}
ggplot(data = diamonds) +
  geom_point(mapping = aes(x = carat, y = price))
```

But wait - there's a bunch of overplotting here! So fix it with an alpha channel:
```{r}
ggplot(data = diamonds) +
  geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100)
```

Still, this is challenging for large datasets. Binning in multiple dimensions can help - so combining tiling with scatter plots. First, install 'hexbin' package:
```{r}
# install.packages("hexbin")
```

Now plot with squares:
```{r}
ggplot(data = smaller) +
  geom_bin2d(mapping = aes(x = carat, y = price))
```

And with hexagons:
```{r}
ggplot(data = smaller) +
  geom_hex(mapping = aes(x = carat, y = price))
```

Can also bin a continuous variable so it acts like a categorical variable and plot boxplots.
```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))
```

Note, boxplots may look the same even if number of observations they represent are very different. Could fix this by making the width of the boxplot proportional tot he number of points:

```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)), varwidth = TRUE)
```

Can also display the same number of points in each bin:
```{r}
 ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_number(carat, 20)))
```

### 7.5.3.1 Exercises
TODO

### 7.6 Patterns and Models
If a systematic relationship exists between two variables it will pappear as a pattern in the data:

* Could it be due to coincidence?
* How can you describe the relationsihp implied in the pattern?
* How strong is the relationship implied by the pattern?
* What other variables might affect the relationship?
* Does the relationship change if you look at individual subgroups of the data?

Old Faithful erumption lengths vs. wait time between eruptions shows longer wait times are associated with longer eruptions:
```{r}
ggplot(data = faithful) +
  geom_point(mapping = aes(x = eruptions, y = waiting)) +
  xlab("eruption time") + ylab("eruption length")
```

This pattern reveals covariation. If two variables covary, you can use one to make better predictions about the values of the second. If due to causal relationship (a special case), can use the value of one variable to control the value of the second.

Models are tools to extract patterns out of data. In diamonds dataset, hard to understand relationship between cut and price, because cut and carat, and carat and price are tightly related. A model allows removing very strong relationship between price and carat so we can explore the subtleties that remain. Following code fits a model that predicts price and carat, and computes the residuals (the difference between the predicted value and the acutal value). The residuals give us a view of the price of the diamond, once the effect of carat has been removed.

```{r}
library(modelr)

mod <- lm(log(price) ~ log(carat), data = diamonds)

diamonds2 <- diamonds %>%
  add_residuals(mod) %>%
  mutate(resid = exp(resid))

ggplot(data = diamonds2) +
  geom_point(mapping = aes(x = carat, y = resid))
```

Strong relationship between carat and price removed, now can see what expect in relationship between cut and price. Relative to their size, better quality diamonds are more expensive!

### ggplot2 Calls
Note, from now on code will be made less explicit to make quicker to write. For example...
```{r}
ggplot(data = faithful, mapping = aes(x = eruptions)) +
  geom_freqpoly(binwidth = 0.25)
```

can become:
```{r}
ggplot(faithful, aes(eruptions)) +
  geom_freqpoly(binwidth = 0.25)
```

Also, sometimes end of a pipeline will become a plot:
```{r}
diamonds %>%
  count(cut, clarity) %>%
  ggplot(aes(clarity, cut, fill = n)) +
  geom_tile()
```
